<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aether</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
            background: #0a0a0a;
            color: #e0e0e0;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        #status {
            font-size: 0.85rem;
            color: #666;
            margin-bottom: 1rem;
            min-height: 1.2rem;
            transition: color 0.3s;
        }
        #status.active { color: #4ecdc4; }
        #status.error { color: #ff6b6b; }

        /* Live transcript — shows what user is saying in real-time */
        #live-transcript {
            font-size: 0.85rem;
            color: #4ecdc4;
            margin-bottom: 1.5rem;
            min-height: 1.2rem;
            max-width: 500px;
            text-align: center;
            opacity: 0.7;
            font-style: italic;
            transition: opacity 0.2s;
        }
        #live-transcript.active { opacity: 1; font-style: normal; }

        #orb-container {
            position: relative;
            width: 180px;
            height: 180px;
            margin-bottom: 2rem;
            cursor: pointer;
        }

        #orb {
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: radial-gradient(circle at 35% 35%, #1a1a2e, #0a0a15);
            border: 1px solid #1a1a2e;
            transition: all 0.4s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #orb:hover { border-color: #4ecdc4; box-shadow: 0 0 40px rgba(78, 205, 196, 0.1); }

        #orb.listening {
            border-color: #4ecdc4;
            box-shadow: 0 0 60px rgba(78, 205, 196, 0.2);
            animation: pulse 2s ease-in-out infinite;
        }
        #orb.thinking {
            border-color: #a78bfa;
            box-shadow: 0 0 60px rgba(167, 139, 250, 0.2);
            animation: pulse 1.2s ease-in-out infinite;
        }
        #orb.speaking {
            border-color: #f59e0b;
            box-shadow: 0 0 60px rgba(245, 158, 11, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.03); }
        }

        #orb-label {
            font-size: 0.75rem;
            color: #444;
            letter-spacing: 0.1em;
            text-transform: uppercase;
        }

        #conversation {
            position: fixed;
            bottom: 100px;
            left: 50%;
            transform: translateX(-50%);
            width: 90%;
            max-width: 600px;
            max-height: 200px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
            padding: 1rem;
        }

        .message {
            font-size: 0.9rem;
            line-height: 1.5;
            padding: 0.5rem 0;
            opacity: 0;
            animation: fadeIn 0.3s ease forwards;
        }
        .message.user { color: #888; text-align: right; }
        .message.assistant { color: #e0e0e0; }
        .message.streaming { opacity: 1; }

        @keyframes fadeIn { to { opacity: 1; } }

        #controls {
            position: fixed;
            bottom: 30px;
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        .ctrl-btn {
            background: none;
            border: 1px solid #333;
            color: #666;
            padding: 0.5rem 1rem;
            border-radius: 2rem;
            font-size: 0.75rem;
            cursor: pointer;
            transition: all 0.2s;
        }
        .ctrl-btn:hover { border-color: #4ecdc4; color: #4ecdc4; }

        #text-input-container {
            position: fixed;
            bottom: 70px;
            left: 50%;
            transform: translateX(-50%);
            width: 90%;
            max-width: 500px;
            display: none;
        }

        #text-input {
            width: 100%;
            background: #111;
            border: 1px solid #333;
            color: #e0e0e0;
            padding: 0.75rem 1rem;
            border-radius: 2rem;
            font-size: 0.9rem;
            outline: none;
        }
        #text-input:focus { border-color: #4ecdc4; }
    </style>
</head>
<body>
    <div id="status">tap the orb to speak</div>
    <div id="live-transcript"></div>

    <div id="orb-container" onclick="toggleStreaming()">
        <div id="orb">
            <span id="orb-label">aether</span>
        </div>
    </div>

    <div id="conversation"></div>

    <div id="text-input-container">
        <input id="text-input" type="text" placeholder="Type a message..."
               onkeydown="if(event.key==='Enter')sendText()">
    </div>

    <div id="controls">
        <button class="ctrl-btn" onclick="toggleTextMode()">text</button>
        <button class="ctrl-btn" onclick="captureImage()">camera</button>
    </div>

    <script>
        // --- State ---
        let ws = null;
        let isTextMode = false;
        let audioContext = null;

        // --- Streaming STT state ---
        let isStreaming = false;
        let audioStream = null;       // MediaStream from getUserMedia
        let audioProcessor = null;    // ScriptProcessorNode or AudioWorklet
        let streamSource = null;      // MediaStreamAudioSourceNode
        let streamingMessageEl = null;

        // --- Audio playback queue ---
        const audioQueue = [];
        let isPlaying = false;

        // --- Elements ---
        const orb = document.getElementById('orb');
        const orbLabel = document.getElementById('orb-label');
        const statusEl = document.getElementById('status');
        const liveTranscript = document.getElementById('live-transcript');
        const conversation = document.getElementById('conversation');
        const textContainer = document.getElementById('text-input-container');
        const textInput = document.getElementById('text-input');

        // --- WebSocket ---
        function connect() {
            const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            ws = new WebSocket(`${protocol}//${location.host}/ws`);

            ws.onopen = () => {
                setStatus('ready');
                orbLabel.textContent = 'aether';
            };

            ws.onmessage = (event) => {
                const msg = JSON.parse(event.data);

                switch (msg.type) {
                    case 'transcript':
                        handleTranscript(msg.data, msg.interim);
                        break;
                    case 'text_chunk':
                        handleTextChunk(msg.data, msg.index);
                        break;
                    case 'audio_chunk':
                        queueAudio(msg.data);
                        break;
                    case 'stream_end':
                        handleStreamEnd();
                        break;
                    case 'status':
                        setStatus(msg.data, true);
                        break;
                }
            };

            ws.onclose = () => {
                setStatus('disconnected — reconnecting...');
                setTimeout(connect, 2000);
            };

            ws.onerror = () => setStatus('connection error', false, true);
        }

        // --- Streaming STT (v0.02) ---
        async function toggleStreaming() {
            if (isTextMode) return;

            if (isStreaming) {
                stopStreaming();
            } else {
                await startStreaming();
            }
        }

        async function startStreaming() {
            try {
                // Get microphone
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                    }
                });

                // Tell server to open Deepgram connection
                ws.send(JSON.stringify({ type: 'stream_start' }));

                // Set up audio processing to send chunks
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000,
                    });
                }

                streamSource = audioContext.createMediaStreamSource(audioStream);

                // Use ScriptProcessor to capture raw PCM and send as chunks
                // (AudioWorklet is better but ScriptProcessor works everywhere)
                audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);

                audioProcessor.onaudioprocess = (e) => {
                    if (!isStreaming || !ws || ws.readyState !== WebSocket.OPEN) return;

                    const inputData = e.inputBuffer.getChannelData(0);

                    // Convert float32 to int16 PCM
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Send as base64
                    const bytes = new Uint8Array(pcm16.buffer);
                    let binary = '';
                    for (let i = 0; i < bytes.length; i++) {
                        binary += String.fromCharCode(bytes[i]);
                    }
                    ws.send(JSON.stringify({
                        type: 'audio_chunk',
                        data: btoa(binary),
                    }));
                };

                streamSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);

                isStreaming = true;
                setOrbState('listening');
                setStatus('listening...', true);
                liveTranscript.textContent = '';

            } catch (err) {
                console.error('Streaming start error:', err);
                setStatus('microphone access denied', false, true);
            }
        }

        function stopStreaming() {
            isStreaming = false;

            // Disconnect audio processing
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            if (streamSource) {
                streamSource.disconnect();
                streamSource = null;
            }
            if (audioStream) {
                audioStream.getTracks().forEach(t => t.stop());
                audioStream = null;
            }

            // Tell server to close Deepgram connection
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'stream_stop' }));
            }

            liveTranscript.textContent = '';
            setOrbState('idle');
        }

        // --- Handle live transcription ---
        function handleTranscript(text, interim) {
            if (interim) {
                // Show interim (partial) transcript — updates in real-time
                liveTranscript.textContent = text;
                liveTranscript.className = 'active';
            } else {
                // Final transcript — add as user message, clear live display
                liveTranscript.textContent = '';
                liveTranscript.className = '';
                addMessage(text, 'user');
                setOrbState('thinking');
                setStatus('thinking...', true);
            }
        }

        // --- Streaming LLM response ---
        function handleTextChunk(text, index) {
            if (index === 0) {
                streamingMessageEl = document.createElement('div');
                streamingMessageEl.className = 'message assistant streaming';
                streamingMessageEl.textContent = text;
                conversation.appendChild(streamingMessageEl);
                setOrbState('speaking');
                setStatus('speaking...', true);
            } else if (streamingMessageEl) {
                streamingMessageEl.textContent += ' ' + text;
            }
            conversation.scrollTop = conversation.scrollHeight;
        }

        function handleStreamEnd() {
            if (streamingMessageEl) {
                streamingMessageEl.classList.remove('streaming');
                streamingMessageEl = null;
            }
            while (conversation.children.length > 10) {
                conversation.removeChild(conversation.firstChild);
            }
            // If still streaming mic, go back to listening
            if (isStreaming) {
                // Small delay before going back to listening state
                setTimeout(() => {
                    if (isStreaming && !isPlaying) {
                        setOrbState('listening');
                        setStatus('listening...', true);
                    }
                }, 500);
            }
        }

        // --- Audio Queue ---
        function queueAudio(base64Data) {
            audioQueue.push(base64Data);
            if (!isPlaying) playNextInQueue();
        }

        async function playNextInQueue() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                if (!streamingMessageEl) {
                    if (isStreaming) {
                        setOrbState('listening');
                        setStatus('listening...', true);
                    } else {
                        setOrbState('idle');
                    }
                }
                return;
            }

            isPlaying = true;
            setOrbState('speaking');

            const base64Data = audioQueue.shift();
            try {
                // Use a separate context for playback (may have different sample rate)
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                const binaryStr = atob(base64Data);
                const bytes = new Uint8Array(binaryStr.length);
                for (let i = 0; i < binaryStr.length; i++) {
                    bytes[i] = binaryStr.charCodeAt(i);
                }

                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer.slice(0));
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.onended = () => playNextInQueue();
                source.start();
            } catch (err) {
                console.error('Audio playback error:', err);
                playNextInQueue();
            }
        }

        // --- Text Mode ---
        function toggleTextMode() {
            isTextMode = !isTextMode;
            textContainer.style.display = isTextMode ? 'block' : 'none';
            if (isTextMode) {
                if (isStreaming) stopStreaming();
                textInput.focus();
            }
        }

        function sendText() {
            const text = textInput.value.trim();
            if (!text || !ws || ws.readyState !== WebSocket.OPEN) return;

            addMessage(text, 'user');
            ws.send(JSON.stringify({ type: 'text', data: text }));
            textInput.value = '';
            setOrbState('thinking');
            setStatus('thinking...', true);
        }

        // --- Camera ---
        async function captureImage() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment' }
                });

                const video = document.createElement('video');
                video.srcObject = stream;
                video.play();

                await new Promise(resolve => video.onloadedmetadata = resolve);
                await new Promise(resolve => setTimeout(resolve, 500));

                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                canvas.getContext('2d').drawImage(video, 0, 0);
                stream.getTracks().forEach(t => t.stop());

                const dataUrl = canvas.toDataURL('image/jpeg', 0.8);
                const base64 = dataUrl.split(',')[1];

                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'image', data: base64, mime: 'image/jpeg' }));
                    setStatus('image sent — now speak your question', true);
                }
            } catch (err) {
                setStatus('camera access denied', false, true);
                console.error('Camera error:', err);
            }
        }

        // --- UI Helpers ---
        function setOrbState(state) {
            orb.className = state === 'idle' ? '' : state;
            const labels = { idle: 'aether', listening: 'listening', thinking: '...', speaking: '♪' };
            orbLabel.textContent = labels[state] || 'aether';
            if (state === 'idle') setStatus('tap the orb to speak');
        }

        function setStatus(text, active = false, error = false) {
            statusEl.textContent = text;
            statusEl.className = error ? 'error' : (active ? 'active' : '');
        }

        function addMessage(text, role) {
            const div = document.createElement('div');
            div.className = `message ${role}`;
            div.textContent = text;
            conversation.appendChild(div);
            conversation.scrollTop = conversation.scrollHeight;
            while (conversation.children.length > 10) {
                conversation.removeChild(conversation.firstChild);
            }
        }

        // --- Init ---
        connect();
    </script>
</body>
</html>
